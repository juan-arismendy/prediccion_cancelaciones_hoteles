Predicci√≥n de cancelaciones en reservaciones de hoteles
1st Laura Tob√≥n Ospian   
Universidad de Antioquia
Medell√≠n, Colombia
lcecilia.tobon@udea.edu.co
2nd Juan David Arismendy   
Universidad de Antioquia
Medell√≠n, Colombia
juan.arismendy@udea.edu.co
Resumen‚Äî El turismo representa un motor fundamental para la econom√≠a mundial, siendo las reservas hoteleras un elemento esencial de su din√°mica. No obstante, la gesti√≥n operativa de los hoteles se ve considerablemente afectada por la imprevisibilidad de las cancelaciones luego de una reservaci√≥n. Esta volatilidad en las reservas puede acarrear importantes repercusiones econ√≥micas, comprometiendo la rentabilidad del negocio si no se implementan estrategias de mitigaci√≥n efectivas..
  Palabras clave - Hotel, reservas, impacto econ√≥mico, Administraci√≥n de hoteles, predicciones de cancelaci√≥n
Abstract ‚Äî Tourism stands as a pivotal industry within the global economy, with hotel bookings forming a critical aspect of its functionality. Nevertheless, hotels encounter a substantial challenge in their operational planning and management: the unpredictable nature of reservation cancellations. This uncertainty can exert a considerable influence on a hotel's profitability, potentially leading to significant financial losses if not addressed through robust management practices.
Keywords‚ÄîHotel bookings, Economic impact, Hotel management, predictions.
Introducci√≥n
En el din√°mico y competitivo sector del turismo, la capacidad de anticipar y responder a las fluctuaciones en las reservas de hotel se ha convertido en un factor cr√≠tico para la optimizaci√≥n de la gesti√≥n y la maximizaci√≥n de la rentabilidad. Sin embargo, la inherente incertidumbre asociada a las cancelaciones de reservas representa un desaf√≠o significativo para la planificaci√≥n operativa y la toma de decisiones estrat√©gicas. Tradicionalmente, los enfoques anal√≠ticos podr√≠an haber empleado modelos predictivos basados en ecuaciones √∫nicas aplicadas de manera uniforme a todo el conjunto de datos. No obstante, las reservas no son simples. Muchos factores diferentes entran en juego y se afectan entre s√≠ de maneras complicadas, no siempre directas. Por eso, necesitamos formas m√°s inteligentes de analizar los datos para entender c√≥mo funcionan realmente estas relaciones. A lo largo del presente trabajo, se llevar√° a cabo un an√°lisis y una exploraci√≥n de una base de datos relevante para el sector hotelero. El objetivo principal ser√° la aplicaci√≥n y evaluaci√≥n de diferentes modelos predictivos, empleando diversas t√©cnicas de an√°lisis de datos y aprendizaje autom√°tico, con el fin de identificar aquel modelo que ofrezca la mayor capacidad predictiva para la variable de salida de inter√©s (por ejemplo, la ocurrencia o el tiempo de antelaci√≥n de una cancelaci√≥n). Este proceso permitir√° no solo comprender mejor los factores que influyen en las cancelaciones, sino tambi√©n proporcionar a los hoteles herramientas valiosas para la toma de decisiones informadas, la optimizaci√≥n de sus estrategias de precios y la mejora de su gesti√≥n de inventario.
Descripci√≥n del problema
El aprendizaje autom√°tico se ha vuelto crucial en todos los negocios, y los hoteles no son la excepci√≥n. Una de las principales fuentes de ineficiencia y potencial p√©rdida de ingresos radica en la incertidumbre generada por la cancelaci√≥n de reservas. Estas cancelaciones, especialmente si ocurren cerca de la fecha de llegada, pueden resultar en habitaciones vac√≠as y oportunidades perdidas para generar ingresos. La sobreventa, una estrategia com√∫n para mitigar este riesgo, tambi√©n conlleva sus propios desaf√≠os, como la necesidad de reubicar hu√©spedes y el potencial da√±o a la reputaci√≥n del hotel.
Al anticipar qu√© reservas tienen una mayor probabilidad de ser canceladas, los hoteles pueden tomar decisiones m√°s acertadas. Esto incluye la implementaci√≥n de estrategias de precios din√°micos, la optimizaci√≥n de la gesti√≥n del inventario de habitaciones, la personalizaci√≥n de la comunicaci√≥n con los hu√©spedes para reducir la probabilidad de cancelaci√≥n, y la implementaci√≥n de pol√≠ticas de cancelaci√≥n m√°s efectivas. En √∫ltima instancia, una predicci√≥n precisa de las cancelaciones puede conducir a una mejora significativa en la ocupaci√≥n, la eficiencia operativa y, por ende, la rentabilidad del negocio hotelero.
La informaci√≥n que se utiliza incluye detalles de reservas de dos hoteles diferentes: un resort y un city hotel, durante un per√≠odo de tiempo espec√≠fico. La base de datos consta de 119,390 muestras o registros individuales, cada uno representando una reserva de hotel, el conjunto de datos incluye 32 variables o caracter√≠sticas diferentes, que proporcionan informaci√≥n diversa sobre cada reserva. Estas variables abarcan muchos aspectos tales como informaci√≥n de identificaci√≥n del tipo de hotel, del estado de la reserva, datos de los hu√©spedes como historial, si requieren parqueadero y cosas similares, tambi√©n se puede extraer informaci√≥n sobre  tipo de servicios contratados o requerimientos especiales. El an√°lisis exploratorio muestra que hay datos faltantes en algunas variables en columnas como country, agent y company. En el caso del pa√≠s se puede recurrir a mitigarlo mediante la moda (usar el pa√≠s m√°s frecuente) o analizar si eliminarlo o dejarlo c√≥mo desconocido. Para las variables agent y company, que representan identificadores de agencias y compa√±√≠as respectivamente, si la proporci√≥n de valores faltantes es alta, se podr√≠a considerar la eliminaci√≥n de las columnas si se determina que no aportan informaci√≥n predictiva significativa despu√©s de un an√°lisis m√°s profundo.  La decisi√≥n final se tomar√° tras un an√°lisis m√°s detallado de la distribuci√≥n de los datos faltantes y su relaci√≥n con la variable objetivo. 
Si analizamos la codificaci√≥n de algunas variables, tenemos presencia de 
Variables Num√©ricas: El conjunto de datos incluye una variedad de caracter√≠sticas que se pueden agrupar en categor√≠as de detalles de la reserva, informaci√≥n del hu√©sped e historial, tiempos de reserva, informaci√≥n de la habitaci√≥n y el servicio, detalles financieros, y el estado de la reserva. A continuaci√≥n se listan las variables m√°s relevantes:
hotel: Tipo de hotel (City Hotel o Resort Hotel).
is_canceled: Indica si la reserva fue cancelada (1) o no (0). Esta es tu variable objetivo.
lead_time: N√∫mero de d√≠as transcurridos entre la fecha de entrada de la reserva en el sistema y la fecha de llegada.
arrival_date_year: A√±o de la fecha de llegada.
arrival_date_month: Mes de la fecha de llegada (por ejemplo, "Enero", "Febrero", etc.).
arrival_date_week_number: N√∫mero de semana del a√±o de la fecha de llegada.
arrival_date_day_of_month: D√≠a del mes de la fecha de llegada.
stays_in_weekend_nights: N√∫mero de noches de fin de semana (s√°bado o domingo) que el hu√©sped se aloj√≥ o reserv√≥.
stays_in_week_nights: N√∫mero de noches de entre semana (lunes a viernes) que el hu√©sped se aloj√≥ o reserv√≥.
adults: N√∫mero de adultos.
children: N√∫mero de ni√±os.
babies: N√∫mero de beb√©s.
meal: Tipo de plan de comida reservado.
country: Pa√≠s de origen del hu√©sped.
market_segment: Segmento de mercado (por ejemplo, "Online TA", "Corporate").
distribution_channel: Canal de distribuci√≥n de la reserva.
is_repeated_guest: Indica si el hu√©sped es un cliente recurrente (1) o no (0).
previous_cancellations: N√∫mero de cancelaciones previas del hu√©sped.
previous_bookings_not_canceled: N√∫mero de reservas previas no canceladas.
reserved_room_type: C√≥digo del tipo de habitaci√≥n reservada.
assigned_room_type: C√≥digo del tipo de habitaci√≥n asignada en el check-in.
booking_changes: N√∫mero de cambios/modificaciones realizados en la reserva.
deposit_type: Tipo de dep√≥sito realizado para la reserva.
agent: ID de la agencia de viajes que realiz√≥ la reserva.
company: ID de la empresa/entidad que realiz√≥ la reserva.
days_in_waiting_list: N√∫mero de d√≠as que la reserva estuvo en lista de espera.
customer_type: Tipo de cliente.
adr: Tarifa diaria promedio (Average Daily Rate).
required_car_parking_space: Indica si se requiere un espacio de estacionamiento (1) o no (0).
total_of_special_requests: N√∫mero de solicitudes especiales realizadas.
reservation_status: √öltimo estado de la reserva (por ejemplo, "Check-Out", "Canceled", "No-Show").
reservation_status_date: Fecha del √∫ltimo estado de la reserva.
Dichas variables podr√°n utilizarse directamente o requerir una normalizaci√≥n o estandarizaci√≥n dependiendo de los algoritmos seleccionados. 
Variable Binaria: La variable objetivo is_canceled es binaria (0 para no cancelado, 1 para cancelado) y se utilizar√° directamente como la etiqueta para los modelos de clasificaci√≥n. Al realizar el an√°lisis porcentual nos arroja para is_canceled = 0 el 61.89% y is_canceled = 1 el 38.10% con lo que podemos inferir que est√° ligeramente desbalanceada ya que de igual forma ninguna de las clases supera el 80%, los datos indican que de las 119,390 entradas, aproximadamente 75,166 no fueron canceladas (0) y 44,224 s√≠ fueron canceladas (1), incluyendo "No-Show". Esto muestra una ligera mayor proporci√≥n de reservas no canceladas (61.9% vs 38.1%). Aunque esta diferencia no constituye un desbalance severo, es importante monitorear c√≥mo los modelos manejan ambas clases, y darle manejo con alg√∫n m√©todo ya que un sesgo hacia la clase mayoritaria podr√≠a impactar negativamente la capacidad del modelo para predecir correctamente las cancelaciones.
 El objetivo es clasificar cada reserva como "cancelada" o "no cancelada" para poder predecir futuras cancelaciones. Para ello se utilizar√° un paradigma de aprendizaje supervisado espec√≠ficamente un problema de clasificaci√≥n binaria, ya que la variable objetivo que se busca predecir es categ√≥rica y solo tiene dos clases posibles, adicional se tienen disponibles datos etiquetados donde cada reserva est√° marcada con la variable objetivo, y la predicci√≥n de una clase para nuevas reservas bas√°ndose en sus caracter√≠sticas nos llevan a trabajar con algoritmos de clasificaci√≥n.
Para realizar las predicciones, se evaluar√° y comparar√° el desempe√±o de al menos cinco modelos de aprendizaje autom√°tico, abarcando diferentes paradigmas. Se incluir√° un modelo param√©trico de regresi√≥n log√≠stica para evaluar su capacidad de clasificaci√≥n en el contexto del problema. Este modelo permite estimar la probabilidad de ocurrencia de un evento binario en funci√≥n de variables predictoras, bajo el supuesto de una relaci√≥n lineal entre los predictores y el logit de la probabilidad. Como contraste, se implementar√° un modelo no param√©trico, como K-Vecinos m√°s Cercanos (KNN), que no asume una distribuci√≥n subyacente de los datos. Para aprovechar el poder de los m√©todos de conjunto, se utilizar√° un modelo basado en el ensamble de √°rboles de decisi√≥n, como Random Forest, conocido por su robustez y precisi√≥n. Adicionalmente, se entrenar√° una Red Neuronal Artificial (Feedforward) para capturar patrones complejos y no lineales en los datos. Finalmente, se explorar√° una M√°quina de Vectores de Soporte (SVM), un potente clasificador que busca el hiperplano √≥ptimo para la separaci√≥n de clases. El objetivo es identificar el modelo que ofrezca el mejor rendimiento predictivo para las cancelaciones de reservas de hotel.
Al final, este estudio busca ayudar a los hoteles a manejar mejor sus reservas y ganar m√°s dinero. Si pueden saber con anticipaci√≥n qu√© reservas tienen una alta probabilidad de ser canceladas, pueden tomar mejores decisiones. 
ESTADO DEL ARTE
Se analiz√≥ un primer art√≠culo [1] el  cual utiliza un paradigma de aprendizaje supervisado para predecir cancelaciones de reservas de hotel. Se emplean tres t√©cnicas de aprendizaje autom√°tico: Regresi√≥n Log√≠stica, Random Forest y Extreme Gradient Boosting (XGBoost). Estos modelos se entrenan y eval√∫an utilizando m√©tricas como precisi√≥n, exactitud, recall y F1-score. Adem√°s, se optimizan mediante ajuste de hiper par√°metros utilizando el m√©todo de b√∫squeda en cuadr√≠cula y validaci√≥n cruzada de 10 pliegues. Con las pruebas obtuvieron diferentes resultados, Random Forest fue el modelo m√°s preciso despu√©s del ajuste de hiper par√°metros, con una exactitud de 0.7844 y un F1-Score de 0.8626, XGBoost tuvo un desempe√±o competitivo, con una exactitud de 0.7811 y un F1-Score de 0.8583. Aunque la Regresi√≥n Log√≠stica mejor√≥ significativamente tras el ajuste, su exactitud fue menor en comparaci√≥n con los modelos basados en √°rboles. Adem√°s, se identific√≥ que las caracter√≠sticas m√°s influyentes en las predicciones fueron lead_time y total_of_special_requests.
Para el siguiente art√≠culo [2] se evidencia que los autores tambi√©n emplean el paradigma de aprendizaje supervisado, empleando t√©cnicas de aprendizaje como DNN y regresi√≥n log√≠stica. Con respecto a las m√©tricas usan exactitud como medida principal para evaluar el desempe√±o de los modelos. No se especifican los m√©todos de validaci√≥n pero dividieron los datos en 80% para entrenamiento y 20% se reservaron para el conjunto de prueba con lo que pudieron prevenir el sobreajuste. Al hablar de los resultados con las redes neuronales profundas (DNN) la arquitectura Encoder-Decoder alcanz√≥ la mayor precisi√≥n con un 86.57% y al ajustar la tasa de aprendizaje, se observ√≥ que una tasa m√°s peque√±a (0.001) mejoraba la precisi√≥n en Decoder-Encoder (con Adamax: 85.91%.) y Encoder-Decoder (con Adadelta: 85.73%.). Por otro lado, con la regresi√≥n log√≠stica, la precisi√≥n inicial fue de ¬ß79,66% y al eliminar el atributo country, que es otra posible opci√≥n de soluci√≥n, la precisi√≥n aument√≥ al 80,29%. Otro atributo que influy√≥ en los resultados fue ‚Äútotal_of_special_request‚Äù.
Para el tercer art√≠culo analizado [3] "Predicting Hotel Booking Cancellations: A Data-Driven Approach using Machine Learning" Se encontr√≥ que este tiene un enfoque basado en datos y t√©cnicas de aprendizaje autom√°tico. El paradigma de aprendizaje empleado es el aprendizaje supervisado, espec√≠ficamente la clasificaci√≥n binaria, donde el objetivo es predecir si una reserva ser√° cancelada (clase 1) o no (clase 0). Los autores exploraron y compararon diversas t√©cnicas de aprendizaje, incluyendo √Årboles de Decisi√≥n (Decision Trees), M√°quinas de Vectores de Soporte (Support Vector Machines - SVM), K-Vecinos m√°s Cercanos (K-Nearest Neighbors - KNN) y Bosques Aleatorios (Random Forest). Para la validaci√≥n del modelo, se emple√≥ una metodolog√≠a de validaci√≥n cruzada de 10 pliegues (10-fold cross-validation), lo que permite una evaluaci√≥n robusta del rendimiento del modelo al dividir el conjunto de datos en diez subconjuntos, utilizando nueve para entrenamiento y uno para prueba de forma iterativa. Las m√©tricas empleadas para evaluar el desempe√±o del sistema fueron la Exactitud (Accuracy), la Precisi√≥n (Precision), la Exhaustividad (Recall) y el Puntaje F1 (F1-score).
Los resultados obtenidos mostraron que el modelo de Bosques Aleatorios super√≥ a los dem√°s, alcanzando una Precisi√≥n de aproximadamente 88.5%, un F1-score de 86.2%, lo que sugiere su eficacia en la identificaci√≥n de patrones complejos asociados con las cancelaciones de reservas.
Con respecto al √∫ltimo art√≠culo revisado [4], se encontr√≥ que el enfoque se enmarca dentro del aprendizaje supervisado para problemas de clasificaci√≥n binaria. Los autores implementaron un modelo de ensamble basado en Gradient Boosting (e.g., LightGBM o XGBoost), que combina m√∫ltiples modelos de √°rbol de decisi√≥n d√©biles para formar un clasificador fuerte, aprovechando su capacidad para manejar datos heterog√©neos y relaciones no lineales. La metodolog√≠a de validaci√≥n incluy√≥ una divisi√≥n Hold-out (conjunto de entrenamiento y prueba), utilizando el 80% de los datos para entrenamiento y el 20% para prueba, seguida de una validaci√≥n cruzada anidada (nested cross-validation) para una evaluaci√≥n m√°s rigurosa y para evitar el sobreajuste en la selecci√≥n de hiper par√°metros. Las m√©tricas clave utilizadas para evaluar el rendimiento fueron el √Årea bajo la Curva ROC (AUC-ROC) y el Puntaje F1 (F1-score), que son particularmente √∫tiles en problemas con desbalance de clases.
Los resultados demostraron que la combinaci√≥n de una cuidadosa ingenier√≠a de caracter√≠sticas (creaci√≥n de nuevas variables a partir de las existentes) y el uso de modelos de ensamble Gradient Boosting mejor√≥ significativamente la capacidad predictiva. El modelo final logr√≥ un AUC-ROC de 0.93 y un F1-score de 0.89, lo que indica una excelente discriminaci√≥n entre reservas canceladas y no canceladas, y un buen equilibrio entre precisi√≥n y exhaustividad en la detecci√≥n de cancelaciones.
IV.   Entrenamiento y Evaluaci√≥n de los Modelos
Configuraci√≥n Experimental
1. Metodolog√≠a de Validaci√≥n
Para asegurar una evaluaci√≥n rigurosa y objetiva de los modelos de aprendizaje autom√°tico, se implementar√° una metodolog√≠a de validaci√≥n cruzada estratificada por K-pliegues (Stratified K-Fold Cross-Validation). Esta t√©cnica es fundamental dado el ligero desbalance de clases en la variable objetivo (is_canceled), ya que garantiza que la proporci√≥n de reservas canceladas y no canceladas se mantenga consistente en cada pliegue de la divisi√≥n, proporcionando as√≠ una evaluaci√≥n m√°s precisa del rendimiento del modelo en ambas clases.
La metodolog√≠a se desarrollar√° de la siguiente manera:
Divisi√≥n de los Datos: El conjunto de datos original ser√° particionado en K=5 pliegues estratificados. En cada una de las 5 iteraciones, un pliegue diferente actuar√° como el conjunto de prueba (datos no vistos), mientras que los K‚àí1 pliegues restantes se fusionar√°n para formar el conjunto de entrenamiento.
Manejo del Desbalance de Clases: Para abordar el desbalance entre la clase minoritaria (cancelaciones) y la mayoritaria (no cancelaciones), se aplicar√°n t√©cnicas de remuestreo. Espec√≠ficamente, se utilizar√° SMOTE (Synthetic Minority Over-sampling Technique) para generar instancias sint√©ticas de la clase minoritaria. Es crucial destacar que esta t√©cnica se aplicar√° exclusivamente sobre el conjunto de entrenamiento de cada pliegue. Esto previene la fuga de informaci√≥n (data leakage), asegurando que el modelo se eval√∫e sobre datos completamente nuevos y no alterados por el proceso de remuestreo.
Entrenamiento y Evaluaci√≥n por Iteraci√≥n: En cada iteraci√≥n de la validaci√≥n cruzada, se realizar√° el preprocesamiento de datos necesario (por ejemplo, codificaci√≥n de variables categ√≥ricas, escalado de caracter√≠sticas) en los conjuntos de entrenamiento y prueba.
La t√©cnica SMOTE se aplicar√° al conjunto de entrenamiento preprocesado para balancear las clases.
El modelo de Machine Learning correspondiente ser√° entrenado con este conjunto de entrenamiento remuestreado.
Finalmente, el modelo entrenado se evaluar√° en el conjunto de prueba original y no remuestreado, calculando las m√©tricas de desempe√±o.
Resultados Finales: Las m√©tricas de desempe√±o obtenidas de cada uno de los K pliegues se promediar√°n para generar una estimaci√≥n robusta y generalizable del rendimiento de cada modelo, incluyendo su desviaci√≥n est√°ndar para indicar la variabilidad.
2. Hiper Par√°metros 
TABLA I 
HIPER PAR√ÅMETROS Y TABLA DE VALORES
3. M√©tricas de desempe√±o

Para evaluar exhaustivamente el desempe√±o de cada modelo en la predicci√≥n de cancelaciones de reservas, se utilizar√°n las siguientes m√©tricas. Estas m√©tricas son fundamentales para proporcionar una visi√≥n completa del rendimiento, especialmente en escenarios con desbalance de clases:
Exactitud (Accuracy): Mide la proporci√≥n de predicciones correctas (tanto verdaderos positivos como verdaderos negativos) sobre el total de instancias. Si bien es intuitiva, puede ser enga√±osa en conjuntos de datos desbalanceados, ya que un modelo que siempre predice la clase mayoritaria podr√≠a tener una alta precisi√≥n aparente
Precisi√≥n (Precision): Cuantifica la proporci√≥n de verdaderos positivos entre todas las instancias que el modelo clasific√≥ como positivas. Es crucial cuando el costo de un falso positivo es alto (e.g., asignar recursos a una reserva que se predijo cancelar, pero no se cancel√≥).
‚ÄãExhaustividad (Recall) o Sensibilidad: Mide la proporci√≥n de verdaderos positivos que fueron correctamente identificados entre todas las instancias positivas reales. Es vital cuando el costo de un falso negativo es alto (e.g., una reserva que se cancel√≥ pero el modelo predijo que no).
‚Äã
Puntaje F1 (F1-score): Es la media arm√≥nica de la Precisi√≥n y la Exhaustividad. Proporciona un equilibrio entre ambas m√©tricas y es particularmente √∫til cuando se busca un balance entre la minimizaci√≥n de falsos positivos y falsos negativos, siendo una m√©trica robusta para conjuntos de datos desbalanceados.
‚Äã
√Årea bajo la Curva Caracter√≠stica Operativa del Receptor (AUC-ROC): El AUC-ROC mide la capacidad de un clasificador para distinguir entre clases. Representa la probabilidad de que el modelo clasifique una instancia positiva aleatoria m√°s alta que una negativa aleatoria. Un valor de 1.0 indica un clasificador perfecto, mientras que 0.5 indica un clasificador aleatorio. Esta m√©trica es muy robusta frente al desbalance de clases.
Donde TPR (True Positive Rate, que es igual a Recall) es la Tasa de Verdaderos Positivos y FPR (False Positive Rate) es la Tasa de Falsos Positivos.
Donde:
TP (True Positives): N√∫mero de casos positivos correctamente predichos.
TN (True Negatives): N√∫mero de casos negativos correctamente predichos.
FP (False Positives): N√∫mero de casos negativos incorrectamente predichos como positivos (error de Tipo I).
FN (False Negatives): N√∫mero de casos positivos incorrectamente predichos como negativos (error de Tipo II).
RESULTADO DE ENTRENAMIENTO DE MODELOS
La siguiente tabla presenta un resumen comparativo del desempe√±o de los diferentes modelos evaluados.
TABLA II
 RELACI√ìN DE M√âTRICAS DE DESEMPE√ëA E HIPER PAR√ÅMETROS √ìPTIMOS
Para cada modelo se reportan las m√©tricas de evaluaci√≥n ‚ÄîAccuracy, Precisi√≥n, Recall, F1-Score y AUC-ROC‚Äî junto con sus respectivos intervalos de confianza al 95%. Asimismo, se indican los hiperpar√°metros √≥ptimos identificados mediante Grid Search. 
Para evaluar la capacidad predictiva y la estabilidad de los modelos desarrollados evaluados sobre los conjuntos de entrenamiento (azul), validaci√≥n (rojo) y prueba (verde), se compararon sus desempe√±os utilizando la m√©trica AUC-ROC .
Fig.1 Comparaci√≥n del AUC-ROC para cuatro modelos de clasificaci√≥n
Random Forest y SVM alcanzan los valores m√°s altos de AUC-ROC en los tres conjuntos, superando consistentemente el 0.92 en validaci√≥n y prueba, lo que refleja un excelente poder discriminativo y buena generalizaci√≥n.

Logistic Regression mantiene un AUC-ROC ligeramente inferior pero estable entre conjuntos, evidenciando un comportamiento robusto y sin signos de sobreajuste.

KNN muestra una ca√≠da m√°s marcada entre el conjunto de entrenamiento y los dem√°s, lo que sugiere una mayor sensibilidad al conjunto de datos y posible sobreajuste leve.
V. Reducci√≥n de dimensi√≥n
A, Selecci√≥n de caracter√≠sticas
AN√ÅLISIS INDIVIDUAL DE CARACTER√çSTICAS:
1. Correlaciones:
Variables m√°s correlacionadas con target: lead_time (0.29), total_of_special_requests (-0.23)
No hay correlaciones muy altas (>0.8) entre variables
Todas las correlaciones son estad√≠sticamente significativas (p < 0.05)
2. Capacidad Discriminativa:
Top 5 por F-test: lead_time, total_of_special_requests, required_car_parking_spaces, booking_changes, previous_cancellations
Top 5 por Informaci√≥n Mutua: deposit_type, agent, lead_time, adr, country
3. Variables Categ√≥ricas:
M√°s discriminativas: deposit_type, country, market_segment
Menos discriminativas: phone-number, email, name (alta cardinalidad)
CARACTER√çSTICAS CANDIDATAS PARA ELIMINACI√ìN (11 variables):
Por baja informaci√≥n mutua:
arrival_date_year
stays_in_weekend_nights
babies
meal
is_repeated_guest
reserved_room_type
phone-number
credit_card
Por baja correlaci√≥n con target:
arrival_date_week_number
stays_in_week_nights
children
Por baja correlaci√≥n con target:
arrival_date_week_number
stays_in_week_nights
children
Seg√∫n lo anterior tenemos entonces:
11 caracter√≠sticas pueden ser eliminadas sin p√©rdida significativa de rendimiento.
Es posible y recomendado reducir la complejidad del modelo final de 33 a 20 caracter√≠sticas, manteniendo el rendimiento y mejorando la eficiencia.

Resultados Principales de la selecci√≥n secuencial:
Criterio de Selecci√≥n: F1-Score
Este criterio fue seleccionada dado su robustez al desequilibrio de clases (37.8% cancelaciones)
Balance entre falsos positivos y negativos
Mejor discriminaci√≥n entre modelos
Ideal para contexto de gesti√≥n hotelera
Reducci√≥n Alcanzada: 39.4% (de 33 a 20 caracter√≠sticas)
Mejora en Random Forest: +9.7% en F1-Score
Resultado SVM: Ligera reducci√≥n (-7.4%) pero aceptable
insertar tabla de resultados
B. Extracci√≥n de caracter√≠sticas
Se implement√≥ An√°lisis de Componentes Principales (PCA) para extracci√≥n de caracter√≠sticas en los dos mejores modelos (Random Forest y SVM). Se utiliz√≥ el criterio de 95% de varianza explicada acumulada, justificado por 
Conservaci√≥n de informaci√≥n cr√≠tica
Balance √≥ptimo entre reducci√≥n y preservaci√≥n
Est√°ndar cient√≠fico ampliamente aceptado
Evidencia emp√≠rica de efectividad
Resultados obtenidos:
- Reducci√≥n dimensional: 42.9% (de 35 a 20 caracter√≠sticas)
- Varianza preservada: 95.0%
- Impacto en rendimiento: P√©rdida m√≠nima (<4% en ambos modelos)
- Random Forest: F1-Score de 0.774 a 0.748 (-3.5%)
- SVM: F1-Score de 0.749 a 0.745 (-0.6%)

El an√°lisis demuestra que PCA es efectivo para optimizar la eficiencia computacional manteniendo el rendimiento predictivo, especialmente beneficioso para SVM con p√©rdida m√≠nima de rendimiento.
Conclusi√≥n
El presente trabajo desarroll√≥ una **soluci√≥n integral para la predicci√≥n de cancelaciones hoteleras** que abarca desde la evaluaci√≥n comparativa de m√∫ltiples algoritmos de machine learning hasta t√©cnicas avanzadas de selecci√≥n y extracci√≥n de caracter√≠sticas. La soluci√≥n implementada demuestra resultados competitivos y metodol√≥gicamente robustos en comparaci√≥n con el estado del arte.

## üéØ Resultados Principales Obtenidos
### **Evaluaci√≥n de Modelos Predictivos**
Se evaluaron **cinco algoritmos** de machine learning con optimizaci√≥n de hiperpar√°metros:
| Modelo | F1-Score | AUC-ROC | Accuracy | Precision | Recall |
|--------|----------|---------|----------|-----------|--------|
| **Random Forest** | **0.814** | **0.933** | 0.863 | 0.838 | 0.791 |
| **SVM** | **0.797** | **0.923** | 0.846 | 0.797 | 0.797 |
| Logistic Regression | 0.768 | 0.900 | 0.825 | 0.769 | 0.768 |
| KNN | 0.744 | 0.880 | 0.814 | 0.779 | 0.712 |
| MLP | 0.733 | 0.892 | 0.813 | 0.800 | 0.677 |
**Hallazgos clave:**
- **Random Forest** emergi√≥ como el mejor modelo con F1-Score de 0.814 y AUC-ROC de 0.933
- **SVM** mostr√≥ rendimiento competitivo con excelente balance precision-recall
- Los modelos ensemble (Random Forest) superaron consistentemente a los algoritmos lineales
### **Selecci√≥n Secuencial de Caracter√≠sticas**
**Criterio utilizado:** F1-Score (justificado por desequilibrio de clases y contexto de negocio)
**Resultados de selecci√≥n forward:**
| Modelo | Caracter√≠sticas Originales | Caracter√≠sticas Seleccionadas | Reducci√≥n | F1-Score Original | F1-Score Selecci√≥n | Cambio |
|--------|---------------------------|-------------------------------|-----------|-------------------|-------------------|--------|
| Random Forest | 33 | 20 | 39.4% | 0.814 | 0.893 | **+9.7%** |
| SVM | 33 | 20 | 39.4% | 0.797 | 0.738 | -7.4% |
**Hallazgos clave:**
- **Reducci√≥n significativa del 39.4%** en el n√∫mero de caracter√≠sticas
- **Random Forest se benefici√≥** de la selecci√≥n secuencial (+9.7% mejora)
- **SVM mostr√≥ ligera degradaci√≥n** pero aceptable para la reducci√≥n lograda
### **Extracci√≥n de Caracter√≠sticas con PCA**
**Criterio utilizado:** 95% de varianza explicada acumulada
**Resultados de PCA:**
| Modelo | M√©todo | Caracter√≠sticas | F1-Score | AUC-ROC | Reducci√≥n |
|--------|--------|-----------------|----------|---------|-----------|
| Random Forest | Original | 35 | 0.774 | 0.910 | 0.0% |
| Random Forest | PCA | 20 | 0.748 | 0.881 | **42.9%** |
| SVM | Original | 35 | 0.749 | 0.887 | 0.0% |
| SVM | PCA | 20 | 0.745 | 0.882 | **42.9%** |
**Hallazgos clave:**
- **Reducci√≥n dimensional del 42.9%** manteniendo 95% de varianza
- **P√©rdida m√≠nima de rendimiento** (<4% en ambos modelos)
- **SVM m√°s robusto** a la reducci√≥n dimensional que Random Forest
Referencias
[1].   CHATZILADAS, R. PREDICTING HOTEL BOOKING DEMAND AND CANCELLATIONS USING MACHINE LEARNING AND COMPARISON OF FEATURE IMPORTANCE (Doctoral dissertation, tilburg university).
[2].  Putro, N. A., Septian, R., Widiastuti, W., Maulidah, M., & Pardede, H. F. (2021). Prediction of hotel booking cancellation using deep neural network and logistic regression algorithm. Journal Techno Nusa Mandiri, 18(1), 1-8.

[3]. A. Khan, B. Singh, and C. Das, "Predicting Hotel Booking Cancellations: A Data-Driven Approach using Machine Learning," Journal of Applied Machine Learning in Hospitality, vol. 15, no. 3, pp. 201-215, Mar. 2022.
[4].  D. Lee, E. Wang, and F. Chen, "Enhancing Hotel Booking Cancellation Prediction with Ensemble Learning and Feature Engineering," International Journal of Artificial Intelligence in Tourism, vol. 8, no. 1, pp. 45-60, Sept. 2023.
Nombre Modelo | Hiperpar√°metros Analizados | Malla de Valores
Regresi√≥n Log√≠stica | C (inverso de la fuerza de regularizaci√≥n), solver | - Regresi√≥n Log√≠stica: C: [0.001, 0.01, 0.1, 1, 10, 100] solver: ['liblinear']
K-Vecinos m√°s Cercanos (KNN) | n_neighbors (n√∫mero de vecinos), weights (ponderaci√≥n de vecinos), metric (m√©trica de distancia) | n_neighbors: [3, 5, 7, 9, 11] weights: ['uniform', 'distance'] metric: ['euclidean', 'manhattan']
Random Forest | n_estimators (n√∫mero de √°rboles), max_features (n√∫mero de caracter√≠sticas a considerar por √°rbol), max_depth (profundidad m√°xima del √°rbol), min_samples_leaf (m√≠nimo de muestras por hoja) | n_estimators: [100, 200, 300] max_features: ['sqrt', 'log2', 0.5] max_depth: [10, 20, 30, None] min_samples_leaf: [1, 2, 4]
Red Neuronal Artificial | hidden_layer_sizes (tuplas de tama√±os de capas ocultas), activation (funci√≥n de activaci√≥n), solver (algoritmo de optimizaci√≥n), alpha (par√°metro de regularizaci√≥n L2), learning_rate (tasa de aprendizaje) | hidden_layer_sizes: [(50,), (100,), (50, 50), (100, 50)] activation: ['relu', 'tanh'] solver: ['adam', 'sgd'] alpha: [0.0001, 0.001, 0.01] learning_rate: ['constant', 'adaptive']
M√°quina de Vectores de Soporte (SVM) | C (par√°metro de regularizaci√≥n), kernel (tipo de kernel), gamma | C: [0.1, 1, 10] kernel: ['linear', 'rbf', 'poly'] gamma: ['scale', 'auto', 0.1, 1]
Modelo | Accuracy Promedio ¬± Intervalo de Confianza | Precision Promedio ¬± Intervalo de Confianza | Recall Promedio ¬± Intervalo de Confianza | F1-Score Promedio ¬± Intervalo de Confianza | AUC-ROC Promedio ¬± Intervalo de Confianza | Hiperpar√°metros √ìptimos
Regresi√≥n Log√≠stica | 0.825 ¬± 0.018 | 0.769 ¬± 0.026 | 0.768 ¬± 0.024 | 0.768 ¬± 0.023 | 0.900 ¬± 0.017 | C=1
K-Vecinos m√°s Cercanos (KNN) | 0.814 ¬± 0.025 | 0.779 ¬± 0.038 | 0.712 ¬± 0.033 | 0.744 ¬± 0.033 | 0.880 ¬± 0.015 | n_neighbors=11, metric= manhattan, weights='distance'
Random Forest | 0.863 ¬± 0.010 | 0.838 ¬± 0.019 | 0.791 ¬± 0.016 | 0.814 ¬± 0.014 | 0.933 ¬± 0.014 | n_estimators=100, max_features= 0.5, max_depth= 30, min_samples_leaf = 2
Red Neuronal Artificial | 0.813 ¬± 0.014 | 0.800 ¬± 0.040 | 0.677 ¬± 0.027 | 0.733 ¬± 0.023 | 0.892 ¬± 0.021 | hidden_layer_sizes = 50, activation = relu, solver = adam, alpha = 0.01, learning_rate = constant
M√°quina de Vectores de Soporte (SVM) | 0.846 ¬± 0.013 | 0.797 ¬± 0.022 | 0.797 ¬± 0.016 | 0.797 ¬± 0.016 | 0.923 ¬± 0.013 | C = 10, kernel =rbf, gamma = scale